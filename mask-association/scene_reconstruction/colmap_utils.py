import os
from pathlib import Path
from typing import Dict, List, Union

import cv2
import deeplake
import pycolmap

from utils.camera_poses import *


def poses_from_reconstruction(reconstruction: pycolmap.Reconstruction) -> HomogeneousTransform:
    """
    Read and return poses (nerfstudio convention) from file generated by colmap.
    """
    qvecs, tvecs = [], []
    for image_id, image in sorted(reconstruction.images.items()):
        qvecs.append(torch.from_numpy(image.qvec))
        tvecs.append(torch.from_numpy(image.tvec))
    qvecs, tvecs = torch.stack(qvecs), torch.stack(tvecs)
    poses = qt_to_matrix4x4(qvecs, tvecs).float()
    return colmap2nerfstudio_poses(poses)


def pycolmap_cameras_from_dataset(ds: deeplake.Dataset) -> Union[pycolmap.Camera, List[pycolmap.Camera]]:
    """ 
    Extract cameras in pycolamp's format
    :param ds: deeplake scan dataset to extract cameras from
    :return: list of cameras for each datapoint, repeating cameras if necessary
    """
    def pycolmap_camera_model_name(name: str): # TODO:: support more camera models
        return 'PINHOLE'

    def pycolmap_camera_from_metadata(metadata: Dict, camera_id: int):
        # print(f'camera id {camera_id}')
        return pycolmap.Camera(
            # id    =camera_id,
            model =pycolmap_camera_model_name(metadata.get('camera_model', 'PINHOLE')), 
            # model = 'PINHOLE', 
            width =metadata['width'], 
            height=metadata['height'],
            params=[metadata[name] for name in ['fx', 'fy', 'cx', 'cy']],
        )

    if 'camera_params' in ds.info:
        return [pycolmap_camera_from_metadata(ds.info['camera_params'], i) for i in range(len(ds))]
    return [
        pycolmap_camera_from_metadata(metadata['camera_params'], i) 
        for i, metadata in enumerate(ds['metadata'])
    ]


def pycolmap_unpack_dataset(path: Path, ds: deeplake.Dataset, instance: str) -> None:
    """ 
    Convert deeplake datasets into file layout accessible by pycolmap, which requires unpacked images/queries file
    that specifies which images to localize.
    :param ds: deeplake scan dataset to unpack
    :param path: path to unpack dataset to
    :param instance: name of container instance
    """
    print(f'Unpacking dataset {ds.path}...') 
    cameras = pycolmap_cameras_from_dataset(ds)
    image_names     = [f'{instance}-{i:04}.png' for i, _ in enumerate(ds['image'])]
    image_filenames = [path/'images'/name for name in image_names]

    def dump_images(path):
        if os.path.exists(path): 
            return
        os.makedirs(path)
        images = ds['image'].numpy()
        for filename, image in zip(image_filenames, images):
            cv2.imwrite(str(filename), cv2.cvtColor(image, cv2.COLOR_RGB2BGR))
    
    def dump_queries(path):
        if os.path.exists(path): 
            return
        lines = [
            f'{filename.name} {camera.model_name} {camera.width} {camera.height} {" ".join(map(str, camera.params))}'
            for filename, camera in zip(image_filenames, cameras)
        ]
        with open(path, 'w') as f: 
            f.write('\n'.join(lines))

    ops = [(dump_images , 'images'), (dump_queries, 'queries.txt')]
    for op, name in ops:
        op(path/name)
    return {
        'cameras'        : cameras,
        'image_names'    : image_names,
        'image_filenames': image_filenames,
    }